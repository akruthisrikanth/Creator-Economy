{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "c9KzJmrZrzpd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "E9uQw9rPsCpx"
   },
   "outputs": [],
   "source": [
    "# Create a BigQuery client\n",
    "client = bigquery.Client.from_service_account_json('/content/drive/MyDrive/tech-cali-b2c-72b3e690e309-Compute-Engine.json')\n",
    "\n",
    "# Define your BigQuery table details\n",
    "project_id = 'tech-cali-b2c'\n",
    "dataset_id = 'CE_Analytics_Layer'\n",
    "table_id = 'Creator_Social_Profile'\n",
    "\n",
    "# Create a reference to the BigQuery table\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Retrieve the data from BigQuery into a DataFrame\n",
    "df_mod = client.query(f\"SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "S1zc5YOosGkG"
   },
   "outputs": [],
   "source": [
    "df = df_mod.drop_duplicates(subset=['artist_id'], keep='first')\n",
    "df = df[df['artist_id'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "aqj8eyfV87da"
   },
   "outputs": [],
   "source": [
    "df.iloc[:,3:] = df.iloc[:,3:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWzbzNmAsI7C",
    "outputId": "21761192-d366-4cbd-a58b-3de9ee36ff42"
   },
   "outputs": [],
   "source": [
    "cols = ['Creator_ID', 'name', 'country_code', 'genres', 'artist_id']\n",
    "columns_select = list(df.drop(cols, axis=1).columns)\n",
    "for col in columns_select:\n",
    "    df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "NsvI5BIGZzBy"
   },
   "outputs": [],
   "source": [
    "df_fi = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PA-Ypnki1Pm"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for Country code\n",
    "le = LabelEncoder()\n",
    "df_fi['country_code_label'] = le.fit_transform(df_fi['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre Score\n",
    "genre_mapping = {'pop' : r'\\b\\w*pop\\w*\\b',\n",
    "                'hip-hop': r'\\b\\w*hip-hop\\w*\\b',\n",
    "                'hip-hop': r'\\b\\w*hip hop\\w*\\b',\n",
    "                'rap': r'\\b\\w*rap\\w*\\b',\n",
    "                'jazz': r'\\b\\w*jazz\\w*\\b',\n",
    "                'rock': r'\\b\\w*rock\\w*\\b',\n",
    "                'latin':r'\\b\\w*latin\\w*\\b',\n",
    "                'psychedelic':r'\\b\\w*psychedelic\\w*\\b',\n",
    "                'punk':r'\\b\\w*punk\\w*\\b',\n",
    "                'metal':r'\\b\\w*metal\\w*\\b',\n",
    "                'reggae': r'\\b\\w*reggae\\w*\\b'}\n",
    "\n",
    "def map_genres(genre_list):\n",
    "    new_lst = []\n",
    "    for value in genre_list.split(','):\n",
    "        for genre, pattern in genre_mapping.items():\n",
    "            if re.search(pattern, value, flags=re.IGNORECASE):\n",
    "                new_lst.append(genre.strip())\n",
    "                break\n",
    "        else:\n",
    "            new_lst.append(value.strip())\n",
    "    return \",\".join(new_lst)\n",
    "\n",
    "df_fi['New_Genres'] = df_fi['genres'].apply(map_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n"
     ]
    }
   ],
   "source": [
    "unique_values = sorted(df_fi['New_Genres'].str.split(',').explode().unique())\n",
    "i = len(unique_values)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mapping = {genre:i+1 for i, genre in enumerate(unique_values)}\n",
    "def calculate_genre_score(genre_list):\n",
    "    genres = genre_list.split(',')\n",
    "    return sum(value_mapping.get(genre, 0) for genre in genres)\n",
    "\n",
    "df_fi['Genre_Score'] = df_fi['New_Genres'].apply(calculate_genre_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "Gcg-rILhizwG"
   },
   "outputs": [],
   "source": [
    "df_new = df_fi.drop(['Creator_ID', 'name', 'country_code', 'genres', 'New_Genres', 'artist_id'], axis=1)\n",
    "df_rf = df_new.drop(df_new.filter(regex='_z_score|_z_score_label|_zscore'), axis=1)\n",
    "\n",
    "df_filled = df_rf.fillna(df_rf.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mice imputation\n",
    "# from fancyimpute import IterativeImputer\n",
    "\n",
    "# data = df_rf.values\n",
    "\n",
    "# imputer = IterativeImputer()\n",
    "# imputed_data = imputer.fit_transform(data)\n",
    "\n",
    "# df_filled = pd.DataFrame(imputed_data, columns=df_rf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity Check using correlation matrix\n",
    "\n",
    "correlation_matrix = df_filled.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity Check using VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Features'] = df_filled.columns\n",
    "vif_data['Variance_Inflation_Factor'] = [variance_inflation_factor(df_filled.values, i) for i in range(df_filled.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Variance_Inflation_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify_followers</td>\n",
       "      <td>4.885527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify_monthly_listeners</td>\n",
       "      <td>4.891506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_likes</td>\n",
       "      <td>3.618120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_talks</td>\n",
       "      <td>1.222217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_followers</td>\n",
       "      <td>2.445107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>twitter_retweets</td>\n",
       "      <td>1.032242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>youtube_channel_views</td>\n",
       "      <td>10.172065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>youtube_daily_video_views</td>\n",
       "      <td>73.431151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>youtube_monthly_video_views</td>\n",
       "      <td>75.075265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TikTok_followers</td>\n",
       "      <td>146.134777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TikTok_Genz_followers</td>\n",
       "      <td>144.619789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TikTok_Genz_followers_percentage</td>\n",
       "      <td>4.159180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TikTok_avg_engagements_per_post</td>\n",
       "      <td>1.902588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TikTok_number_of_top_tracks</td>\n",
       "      <td>15.104940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TikTok_total_creations_for_top_n_tracks</td>\n",
       "      <td>118.303901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TikTok_avg_creations_for_top_n_tracks</td>\n",
       "      <td>225.712989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TikTok_total_views_for_top_n_tracks</td>\n",
       "      <td>1710.593977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TikTok_avg_views_for_top_n_tracks</td>\n",
       "      <td>1825.700089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Instagram_followers</td>\n",
       "      <td>74.423501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Instagram_Genz_followers</td>\n",
       "      <td>77.917002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Instagram_Genz_followers_percentage</td>\n",
       "      <td>15.036049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Instagram_avg_engagements_per_post</td>\n",
       "      <td>1.409819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Youtube_subscribers</td>\n",
       "      <td>163.768942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Youtube_Genz_subscribers</td>\n",
       "      <td>125.520777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Youtube_Genz_subscribers_percentage</td>\n",
       "      <td>28.508275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Youtube_avg_engagements_per_post</td>\n",
       "      <td>1.336270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>country_code_label</td>\n",
       "      <td>4.332946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Genre_Score</td>\n",
       "      <td>3.018210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Features  Variance_Inflation_Factor\n",
       "0                         spotify_followers                   4.885527\n",
       "1                 spotify_monthly_listeners                   4.891506\n",
       "2                            facebook_likes                   3.618120\n",
       "3                            facebook_talks                   1.222217\n",
       "4                         twitter_followers                   2.445107\n",
       "5                          twitter_retweets                   1.032242\n",
       "6                     youtube_channel_views                  10.172065\n",
       "7                 youtube_daily_video_views                  73.431151\n",
       "8               youtube_monthly_video_views                  75.075265\n",
       "9                          TikTok_followers                 146.134777\n",
       "10                    TikTok_Genz_followers                 144.619789\n",
       "11         TikTok_Genz_followers_percentage                   4.159180\n",
       "12          TikTok_avg_engagements_per_post                   1.902588\n",
       "13              TikTok_number_of_top_tracks                  15.104940\n",
       "14  TikTok_total_creations_for_top_n_tracks                 118.303901\n",
       "15    TikTok_avg_creations_for_top_n_tracks                 225.712989\n",
       "16      TikTok_total_views_for_top_n_tracks                1710.593977\n",
       "17        TikTok_avg_views_for_top_n_tracks                1825.700089\n",
       "18                      Instagram_followers                  74.423501\n",
       "19                 Instagram_Genz_followers                  77.917002\n",
       "20      Instagram_Genz_followers_percentage                  15.036049\n",
       "21       Instagram_avg_engagements_per_post                   1.409819\n",
       "22                      Youtube_subscribers                 163.768942\n",
       "23                 Youtube_Genz_subscribers                 125.520777\n",
       "24      Youtube_Genz_subscribers_percentage                  28.508275\n",
       "25         Youtube_avg_engagements_per_post                   1.336270\n",
       "26                       country_code_label                   4.332946\n",
       "27                              Genre_Score                   3.018210"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannon imputation\n",
    "# from impyute.imputation.cs import fast_knn\n",
    "\n",
    "# imputed_data = fast_knn(data, k=5)\n",
    "# df_filled = pd.DataFrame(imputed_data, columns=df_rf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection - PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1: 0.7858\n",
      "PC2: 0.9997\n",
      "PC3: 0.9999\n",
      "PC4: 1.0000\n",
      "PC5: 1.0000\n",
      "PC6: 1.0000\n",
      "PC7: 1.0000\n",
      "PC8: 1.0000\n",
      "PC9: 1.0000\n",
      "PC10: 1.0000\n",
      "PC11: 1.0000\n",
      "PC12: 1.0000\n",
      "PC13: 1.0000\n",
      "PC14: 1.0000\n",
      "PC15: 1.0000\n",
      "PC16: 1.0000\n",
      "PC17: 1.0000\n",
      "PC18: 1.0000\n",
      "PC19: 1.0000\n",
      "PC20: 1.0000\n",
      "PC21: 1.0000\n",
      "PC22: 1.0000\n",
      "PC23: 1.0000\n",
      "PC24: 1.0000\n",
      "PC25: 1.0000\n",
      "PC26: 1.0000\n",
      "PC27: 1.0000\n",
      "PC28: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = df_filled.shape[1]\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "principal_components = pca.fit_transform(df_filled)\n",
    "\n",
    "components_df = pd.DataFrame(\n",
    "    data=principal_components,\n",
    "    columns=['PC{}'.format(i) for i in range(1, n_components + 1)]\n",
    ")\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "explained_variance_ratio_cumulative = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# for i, ratio in enumerate(explained_variance_ratio, 1):\n",
    "#     print(f'PC{i}: {ratio:.4f}')\n",
    "\n",
    "for i, ratio in enumerate(explained_variance_ratio_cumulative, 1):\n",
    "    print(f'PC{i}: {ratio:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important Features: PC1, PC2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.90\n",
    "\n",
    "loadings = pca.components_\n",
    "\n",
    "num_components = np.sum(explained_variance_ratio_cumulative <= threshold) + 1\n",
    "\n",
    "important_features = components_df.columns[:num_components]\n",
    "\n",
    "print(f\"Important Features: {', '.join(important_features)}\")\n",
    "\n",
    "loadings_abs = np.abs(loadings) \n",
    "important_features_indices = np.argsort(loadings_abs, axis=1)[:, ::-1][:, :num_components]  \n",
    "important_features_names = df_filled.columns[important_features_indices.flatten()].tolist()\n",
    "important_features_names = np.array(important_features_names).reshape((num_components, -1))\n",
    "\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = df_filled.drop(['youtube_daily_video_views','youtube_channel_views',\n",
    "           'TikTok_Genz_followers_percentage','Instagram_Genz_followers_percentage', 'Youtube_Genz_subscribers_percentage','TikTok_number_of_top_tracks',\n",
    "           'TikTok_avg_creations_for_top_n_tracks','TikTok_avg_views_for_top_n_tracks'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_pp)\n",
    "\n",
    "scaled_data = scaler.transform(df_pp)\n",
    "\n",
    "column_names = scaler.get_feature_names_out()\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS3u9cvtB7gN"
   },
   "source": [
    "**Train Test Split, Model Building and Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqs1T42ppuOv",
    "outputId": "280b3b85-ee53-4bc2-9380-44e014fb67ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "X = scaled_df.drop('TikTok_total_creations_for_top_n_tracks', axis=1)\n",
    "y = scaled_df['TikTok_total_creations_for_top_n_tracks']\n",
    "\n",
    "test_size_lst = [0.1, 0.2, 0.3, 0.4, 0.5]  \n",
    "test_size_lr = {}\n",
    "test_size_dtr = {}\n",
    "test_size_rf1 = {}\n",
    "test_size_rft = {}\n",
    "test_size_xgb1 = {}\n",
    "test_size_xgbt = {}\n",
    "test_size_ridge = {}\n",
    "test_size_lasso = {}\n",
    "test_size_svm = {}\n",
    "test_size_enet = {}\n",
    "\n",
    "for test_size in test_size_lst:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=123)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    scores_lr = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "    avg_score_lr = scores_lr.mean()\n",
    "    test_size_lr[test_size] = avg_score_lr\n",
    "    \n",
    "    ridge = Ridge()\n",
    "    scores_ridge = cross_val_score(ridge, X_train, y_train, cv=5)\n",
    "    avg_score_ridge = scores_ridge.mean()\n",
    "    test_size_ridge[test_size] = avg_score_ridge\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    scores_lasso = cross_val_score(lasso, X_train, y_train, cv=5)\n",
    "    avg_score_lasso = scores_lasso.mean()\n",
    "    test_size_lasso[test_size] = avg_score_lasso\n",
    "    \n",
    "    alpha = 0.5  \n",
    "    l1_ratio = 0.5  \n",
    "    enet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    scores_enet = cross_val_score(enet, X_train, y_train, cv=5)\n",
    "    avg_score_enet = scores_enet.mean()\n",
    "    test_size_enet[test_size] = avg_score_enet\n",
    "    \n",
    "    svm = SVR(kernel=\"linear\")\n",
    "    scores_svm = cross_val_score(svm, X_train, y_train, cv=5)\n",
    "    avg_score_svm = scores_svm.mean()\n",
    "    test_size_svm[test_size] = avg_score_svm\n",
    "    \n",
    "    dtr = DecisionTreeRegressor()\n",
    "    scores_dtr = cross_val_score(dtr, X_train, y_train, cv=5)\n",
    "    avg_score_dtr = scores_dtr.mean()\n",
    "    test_size_dtr[test_size] = avg_score_dtr\n",
    "    \n",
    "    rf_1 = RandomForestRegressor()\n",
    "    scores_rf_1 = cross_val_score(rf_1, X_train, y_train, cv=5)\n",
    "    avg_score_rf_1 = scores_rf_1.mean()\n",
    "    test_size_rf1[test_size] = avg_score_rf_1\n",
    "    \n",
    "    param_grid = [{\"n_estimators\": [100, 200, 300, 400, 500],\n",
    "              \"max_depth\": [7, 9, 12, 15],\n",
    "              \"min_samples_split\": [5, 7, 12]}]\n",
    "\n",
    "    rf_t = RandomForestRegressor()\n",
    "    grid_cv_1 = GridSearchCV(rf_t, param_grid, cv=2, n_jobs=-1)\n",
    "    scores_rf_t = cross_val_score(grid_cv_1, X_train, y_train, cv=5)\n",
    "    avg_score_rf_t = scores_rf_t.mean()\n",
    "    test_size_rft[test_size] = avg_score_rf_t\n",
    "    \n",
    "    xg_boost = xgb.XGBRegressor()\n",
    "    scores_xgb = cross_val_score(xg_boost, X_train, y_train, cv=5)\n",
    "    avg_score_xgb = scores_xgb.mean()\n",
    "    test_size_xgb1[test_size] = avg_score_xgb\n",
    "    \n",
    "    param_grid = [{'n_estimators': [100, 200, 300],\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              'learning_rate': [0.01, 0.001]}]\n",
    "\n",
    "    xg_b_t = xgb.XGBRegressor()\n",
    "    grid_cv_2 = GridSearchCV(xg_b_t, param_grid, cv=2, n_jobs=-1)\n",
    "    scores_xgb_t = cross_val_score(grid_cv_2, X_train, y_train, cv=5)\n",
    "    avg_score_xgb_t = scores_xgb_t.mean()\n",
    "    test_size_xgbt[test_size] = avg_score_xgb_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 0.5580469793496854,\n",
       " 0.2: 0.5878548535886408,\n",
       " 0.3: 0.5738202202751733,\n",
       " 0.4: 0.5456194649593641,\n",
       " 0.5: 0.46634906999830295}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size_rft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_lr, cv_lr = max(test_size_lr.items(), key=lambda x: x[1])\n",
    "ts_ridge, cv_ridge = max(test_size_ridge.items(), key=lambda x: x[1])\n",
    "ts_lasso, cv_lasso = max(test_size_lasso.items(), key=lambda x: x[1])\n",
    "ts_enet, cv_enet = max(test_size_enet.items(), key=lambda x: x[1])\n",
    "ts_svm, cv_svm = max(test_size_svm.items(), key=lambda x: x[1])\n",
    "ts_dtr, cv_dtr = max(test_size_dtr.items(), key=lambda x: x[1])\n",
    "ts_rf1, cv_rf1 = max(test_size_rf1.items(), key=lambda x: x[1])\n",
    "ts_rft, cv_rft = max(test_size_rft.items(), key=lambda x: x[1])\n",
    "ts_xgb1, cv_xgb1 = max(test_size_xgb1.items(), key=lambda x: x[1])\n",
    "ts_xgbt, cv_xgbt = max(test_size_xgbt.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0.1, 0.5347963534627089), (0.2, 0.5469948246315447), (0.3, 0.5431233075156031), (0.4, 0.5389095977075515), (0.5, 0.48314856957127095)])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size_lr.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {\n",
    "    cv_lr: (lr, \"Linear Regression\", cv_lr, ts_lr),\n",
    "    cv_ridge: (ridge, \"Ridge Regression\", cv_ridge, ts_ridge),\n",
    "    cv_lasso: (lasso, \"Lasso Regression\", cv_lasso, ts_lasso),\n",
    "    cv_enet : (enet, \"Elastic Net Regression\", cv_enet, ts_enet),\n",
    "    cv_svm: (svm, \"SVM\", cv_svm, ts_svm),\n",
    "    cv_dtr: (dtr, \"Decision Tree\", cv_dtr, ts_dtr),\n",
    "    cv_rf1: (rf_1, \"Random Forest (Before Tuning)\", cv_rf1, ts_rf1),\n",
    "    cv_rft: (grid_cv_1, \"Random Forest (After Tuning)\", cv_rft, ts_rft),\n",
    "    cv_xgb1: (xg_boost, \"XGBoost (Before Tuning)\", cv_xgb1, ts_xgb1),\n",
    "    cv_xgbt: (grid_cv_2, \"XGBoost (After Tuning)\", cv_xgbt, ts_xgbt)\n",
    "}\n",
    "\n",
    "best_score = max(model_scores.keys())\n",
    "best_model, best_model_name, best_score, best_test_size = model_scores[best_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "sVYCOu3hn3Pj"
   },
   "outputs": [],
   "source": [
    "# Function to calculate Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "score_log = pd.DataFrame()\n",
    "def score(model, name , x_test, y_test, position):\n",
    "    y_pred = model.predict(x_test)\n",
    "    score_log.loc[position, \"Model\"] = best_model_name\n",
    "    score_log.loc[position, \"R-Square\"] = round(r2_score(y_test, y_pred), 3)\n",
    "    score_log.loc[position,\"MSE\"] = round(mean_squared_error(y_test, y_pred), 3)\n",
    "    score_log.loc[position, \"RMSE\"] = round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "    score_log.loc[position, \"MAE\"] = round(mean_absolute_error(y_test, y_pred), 3)\n",
    "    return score_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R-Square</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (After Tuning)</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  R-Square    MSE   RMSE    MAE\n",
       "1  Random Forest (After Tuning)     0.301  0.308  0.555  0.218"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=best_test_size, random_state=123)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "score(best_model,\" \", X_test, y_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OanOcB9Muf-P"
   },
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 3649it [04:15, 13.73it/s]                                                                       \n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "def model_predict(X):\n",
    "    return best_model.predict(X)\n",
    "\n",
    "explainer = shap.Explainer(model_predict, X)\n",
    "\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "feature_scores = np.abs(shap_values).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fx53XHGNuiuZ",
    "outputId": "d06dc3c5-2d48-450e-8457-845ff79a7239",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_followers</th>\n",
       "      <th>spotify_monthly_listeners</th>\n",
       "      <th>facebook_likes</th>\n",
       "      <th>facebook_talks</th>\n",
       "      <th>twitter_followers</th>\n",
       "      <th>twitter_retweets</th>\n",
       "      <th>youtube_monthly_video_views</th>\n",
       "      <th>TikTok_followers</th>\n",
       "      <th>TikTok_Genz_followers</th>\n",
       "      <th>TikTok_avg_engagements_per_post</th>\n",
       "      <th>TikTok_total_views_for_top_n_tracks</th>\n",
       "      <th>Instagram_followers</th>\n",
       "      <th>Instagram_Genz_followers</th>\n",
       "      <th>Instagram_avg_engagements_per_post</th>\n",
       "      <th>Youtube_subscribers</th>\n",
       "      <th>Youtube_Genz_subscribers</th>\n",
       "      <th>Youtube_avg_engagements_per_post</th>\n",
       "      <th>country_code_label</th>\n",
       "      <th>Genre_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.00919</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.00957</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.417158</td>\n",
       "      <td>0.017655</td>\n",
       "      <td>0.01928</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.025692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spotify_followers  spotify_monthly_listeners  facebook_likes  \\\n",
       "0           0.019816                   0.016518        0.008453   \n",
       "\n",
       "   facebook_talks  twitter_followers  twitter_retweets  \\\n",
       "0          0.0032           0.003826          0.001508   \n",
       "\n",
       "   youtube_monthly_video_views  TikTok_followers  TikTok_Genz_followers  \\\n",
       "0                      0.00919          0.008041                0.00957   \n",
       "\n",
       "   TikTok_avg_engagements_per_post  TikTok_total_views_for_top_n_tracks  \\\n",
       "0                         0.002914                             0.417158   \n",
       "\n",
       "   Instagram_followers  Instagram_Genz_followers  \\\n",
       "0             0.017655                   0.01928   \n",
       "\n",
       "   Instagram_avg_engagements_per_post  Youtube_subscribers  \\\n",
       "0                            0.013025             0.009894   \n",
       "\n",
       "   Youtube_Genz_subscribers  Youtube_avg_engagements_per_post  \\\n",
       "0                  0.024955                          0.008373   \n",
       "\n",
       "   country_code_label  Genre_Score  \n",
       "0            0.002144     0.025692  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_scores = best_model.feature_importances_\n",
    "\n",
    "feature_imp = pd.DataFrame([feature_scores], columns = X.columns)\n",
    "\n",
    "feature_imp = feature_imp.reset_index(drop=True)\n",
    "\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your BigQuery project ID and credentials\n",
    "project_id = 'tech-cali-b2c'\n",
    "credentials = service_account.Credentials.from_service_account_file('/content/drive/MyDrive/tech-cali-b2c-72b3e690e309-Compute-Engine.json')\n",
    "\n",
    "# Define the BigQuery table name and dataset ID\n",
    "dataset_id = 'CE_ML_Layer'\n",
    "table_name = 'Feature_Importance'\n",
    "\n",
    "# Write the dataframe to BigQuery\n",
    "pandas_gbq.to_gbq(feature_imp, f'{dataset_id}.{table_name}', project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "\n",
    "print('Data moved to BigQuery successfully!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
